{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e05080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:02<00:00, 3.34MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 138kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.54MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.46MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "[에폭 1/200] 판별자 손실: 0.2047 | 생성자 손실: 5.4901\n",
      "[에폭 2/200] 판별자 손실: 0.2045 | 생성자 손실: 5.0471\n",
      "[에폭 3/200] 판별자 손실: 1.2149 | 생성자 손실: 2.4304\n",
      "[에폭 4/200] 판별자 손실: 0.3515 | 생성자 손실: 3.2370\n",
      "[에폭 5/200] 판별자 손실: 0.1276 | 생성자 손실: 4.0042\n",
      "[에폭 6/200] 판별자 손실: 0.1598 | 생성자 손실: 4.5023\n",
      "[에폭 7/200] 판별자 손실: 0.1207 | 생성자 손실: 4.0480\n",
      "[에폭 8/200] 판별자 손실: 0.0652 | 생성자 손실: 5.5192\n",
      "[에폭 9/200] 판별자 손실: 0.0627 | 생성자 손실: 5.4869\n",
      "[에폭 10/200] 판별자 손실: 0.2141 | 생성자 손실: 7.0564\n",
      ">>> 샘플 이미지 저장 완료: samples/epoch_10.png\n",
      "[에폭 11/200] 판별자 손실: 0.4302 | 생성자 손실: 5.8608\n",
      "[에폭 12/200] 판별자 손실: 0.3180 | 생성자 손실: 3.5773\n",
      "[에폭 13/200] 판별자 손실: 0.1020 | 생성자 손실: 5.6188\n",
      "[에폭 14/200] 판별자 손실: 0.1926 | 생성자 손실: 3.0638\n",
      "[에폭 15/200] 판별자 손실: 0.2016 | 생성자 손실: 3.1447\n",
      "[에폭 16/200] 판별자 손실: 0.4160 | 생성자 손실: 4.8339\n",
      "[에폭 17/200] 판별자 손실: 0.1193 | 생성자 손실: 5.5106\n",
      "[에폭 18/200] 판별자 손실: 0.1855 | 생성자 손실: 4.8531\n",
      "[에폭 19/200] 판별자 손실: 0.1218 | 생성자 손실: 4.6765\n",
      "[에폭 20/200] 판별자 손실: 0.2142 | 생성자 손실: 4.8649\n",
      ">>> 샘플 이미지 저장 완료: samples/epoch_20.png\n",
      "[에폭 21/200] 판별자 손실: 0.2410 | 생성자 손실: 6.2003\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# GAN 기반 이미지 생성 모델 구현 (MNIST/FashionMNIST)\n",
    "# ==============================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Generator 정의\n",
    "# -----------------------------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 28*28),\n",
    "            nn.Tanh()   # 출력값 범위: [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z).view(-1, 1, 28, 28)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Discriminator 정의\n",
    "# -----------------------------\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()   # 진짜일 확률 반환\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. 데이터 전처리 및 로더\n",
    "# -----------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))   # [-1, 1] 정규화\n",
    "])\n",
    "\n",
    "# MNIST 사용 (FashionMNIST으로 바꾸려면 아래 주석 해제)\n",
    "dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "# dataset = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. 모델, 손실 함수, 옵티마이저\n",
    "# -----------------------------\n",
    "z_dim = 100\n",
    "G = Generator(z_dim)\n",
    "D = Discriminator()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "opt_G = optim.Adam(G.parameters(), lr=0.0002)\n",
    "opt_D = optim.Adam(D.parameters(), lr=0.0002)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. 학습 루프\n",
    "# -----------------------------\n",
    "epochs = 200  # MNIST 기준 권장: 200~300\n",
    "os.makedirs(\"samples\", exist_ok=True)\n",
    "fixed_noise = torch.randn(64, z_dim)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    for real, _ in loader:\n",
    "        bs = real.size(0)\n",
    "\n",
    "        # -----------------\n",
    "        # (1) Discriminator 학습\n",
    "        # -----------------\n",
    "        noise = torch.randn(bs, z_dim)\n",
    "        fake = G(noise)\n",
    "\n",
    "        D_real = D(real)\n",
    "        D_fake = D(fake.detach())\n",
    "\n",
    "        loss_D = criterion(D_real, torch.ones_like(D_real)) + \\\n",
    "                 criterion(D_fake, torch.zeros_like(D_fake))\n",
    "\n",
    "        opt_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        opt_D.step()\n",
    "\n",
    "        # -----------------\n",
    "        # (2) Generator 학습\n",
    "        # -----------------\n",
    "        D_fake = D(fake)\n",
    "        loss_G = criterion(D_fake, torch.ones_like(D_fake))  # 가짜 이미지를 진짜로 속이기\n",
    "\n",
    "        opt_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        opt_G.step()\n",
    "\n",
    "    # -----------------\n",
    "    # 에폭 결과 출력\n",
    "    # -----------------\n",
    "    print(f\"[에폭 {epoch}/{epochs}] 판별자 손실: {loss_D.item():.4f} | 생성자 손실: {loss_G.item():.4f}\")\n",
    "\n",
    "    # 10 에폭마다 샘플 이미지 저장\n",
    "    if epoch % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            fake = G(fixed_noise)\n",
    "            save_image(fake, f\"samples/epoch_{epoch}.png\", nrow=8, normalize=True)\n",
    "            print(f\">>> 샘플 이미지 저장 완료: samples/epoch_{epoch}.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
